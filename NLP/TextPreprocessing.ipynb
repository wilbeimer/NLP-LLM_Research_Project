{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aaccdd3-b9b1-4b24-b249-90fbc18f1ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"I can't wait for the new season of my favorite show!\",\n",
    "    \"The COVID-19 pandemic has affected millions of people worldwide.\",\n",
    "    \"U.S. stocks fell on Friday after news of rising inflation.\",\n",
    "    \"<html><body>Welcome to the website!</body></html>\",\n",
    "    \"Python is a great programming language!!! ??\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d51dba-65bc-44a5-bc74-d56239b7882c",
   "metadata": {},
   "source": [
    "## convert to lowercase, remove punctuation, numbers, special characters, and HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a44d514-1568-4a61-9968-a73e2874812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1748dd-e00a-4abe-af29-355e50a3ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c83ed3f-a950-40d4-9bc7-3d4ff1ad61e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i cant wait for the new season of my favorite show', 'the covid pandemic has affected millions of people worldwide', 'us stocks fell on friday after news of rising inflation', 'htmlbodywelcome to the websitebodyhtml', 'python is a great programming language ']\n"
     ]
    }
   ],
   "source": [
    "cleaned_corpus = [clean_text(doc) for doc in corpus]\n",
    "print(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e6e8d-d5ee-42c6-8eeb-ee8d46481432",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3166bae-8162-466b-b5bf-dcd33ef52c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'cant', 'wait', 'for', 'the', 'new', 'season', 'of', 'my', 'favorite', 'show'], ['the', 'covid', 'pandemic', 'has', 'affected', 'millions', 'of', 'people', 'worldwide'], ['us', 'stocks', 'fell', 'on', 'friday', 'after', 'news', 'of', 'rising', 'inflation'], ['htmlbodywelcome', 'to', 'the', 'websitebodyhtml'], ['python', 'is', 'a', 'great', 'programming', 'language']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = [doc.split() for doc in cleaned_corpus]\n",
    "print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91c670-bcbf-4106-aa71-4d603ef1ae96",
   "metadata": {},
   "source": [
    "# Another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af63b064-b0a7-4bf8-92f4-9798efa3a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f70896-3120-4df4-8499-f5e0303bbe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['19', 'affected', 'after', 'body', 'can', 'covid', 'favorite',\n",
       "       'fell', 'for', 'friday', 'great', 'has', 'html', 'inflation', 'is',\n",
       "       'language', 'millions', 'my', 'new', 'news', 'of', 'on',\n",
       "       'pandemic', 'people', 'programming', 'python', 'rising', 'season',\n",
       "       'show', 'stocks', 'the', 'to', 'wait', 'website', 'welcome',\n",
       "       'worldwide'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3d2d5b-dedb-404c-aa69-ab15cb7b1663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0]\n",
      " [1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef50b799-1020-4a34-bd41-238b4fec5eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['19 pandemic', 'affected millions', 'after news', 'body html',\n",
       "       'body welcome', 'can wait', 'covid 19', 'favorite show', 'fell on',\n",
       "       'for the', 'friday after', 'great programming', 'has affected',\n",
       "       'html body', 'is great', 'millions of', 'my favorite',\n",
       "       'new season', 'news of', 'of my', 'of people', 'of rising',\n",
       "       'on friday', 'pandemic has', 'people worldwide',\n",
       "       'programming language', 'python is', 'rising inflation',\n",
       "       'season of', 'stocks fell', 'the covid', 'the new', 'the website',\n",
       "       'to the', 'wait for', 'website body', 'welcome to'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "\n",
    "X = vectorizer2.fit_transform(corpus)\n",
    "\n",
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522df24e-9736-463d-8b7a-e613ae08b3aa",
   "metadata": {},
   "source": [
    "# NLTK For Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee51dc2a-1a50-43de-801b-52c97f3d68e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/wilsonbeima/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    STOPWORDS = stopwords.words('english')\n",
    "    \n",
    "    nopunc = [char for char in text if char not in string.punctuation] \n",
    "\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51433a-3652-4b1f-ab6a-a5fd76fcdad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
